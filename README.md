## ✅ **CoinDesk 爬蟲 & 新聞筆記 MVP 開發 Checklist (Hour 1 ~ Hour 100)**

---

### **第一階段：基礎新聞展示 (Day 1 ~ Day 9, 總 72 小時)**

#### 🔹 Day 1: Hour 1 - 8 (8 小時)
- [ ] 明確 **MVP 目標與技術選型** (React, Node.js, PostgreSQL, Express, Cheerio)  
- [ ] 設置 **GitHub Repository**，建立專案架構  
- [ ] **安裝開發環境**  
  - [ ] Node.js  
  - [ ] Express  
  - [ ] PostgreSQL  
  - [ ] React  
  - [ ] TailwindCSS  
- [ ] 建立 **基本的前後端專案目錄結構**  
  - [ ] `backend/`（後端 API 相關程式）  
  - [ ] `frontend/`（前端 React 程式）  
  - [ ] `database/`（SQL Schema & Migration）  
  - [ ] `scraper/`（爬蟲相關程式）  

#### 🔹 Day 2: Hour 9 - 16 (8 小時)
- [ ] 安裝並設定 **`cheerio`**，建立新聞爬蟲 (`npm install cheerio axios`)  
- [ ] 爬取 **CoinDesk** 新聞標題、內容、發布時間、原始連結  
- [ ] 測試爬蟲，確保新聞數據可以正確擷取  

#### 🔹 Day 3: Hour 17 - 24 (8 小時)
- [ ] **翻譯新聞內容 (Google Gemini API)**  
  - [ ] 申請 **Google Gemini API Key**  
  - [ ] 建立 **新聞翻譯 API**  
  - [ ] 翻譯 **新聞標題 & 內文**  
- [ ] **摘要處理 (AI 生成)**  
  - [ ] 使用 AI 產生新聞摘要  
  - [ ] 測試摘要準確性  

#### 🔹 Day 4: Hour 25 - 32 (8 小時)
- [ ] **將新聞 (原文 + 翻譯 + 摘要) 存成 JSON**  
  - [ ] 定義 JSON 格式  
  - [ ] 確保 JSON 結構完整 (標題、內容、翻譯、摘要、時間、來源)  
- [ ] **建立 PostgreSQL `news` 資料表**  
  - [ ] 確保原文、翻譯、摘要都能存入  
  - [ ] 避免重複存入相同新聞  
- [ ] **將 JSON 轉存至 PostgreSQL**  
- [ ] 撰寫 **防止新聞重複儲存的機制**  

#### 🔹 Day 5: Hour 33 - 40 (8 小時)
- [ ] 設計 **Express API**  
  - [ ] `GET /news` - 取得所有新聞  
  - [ ] `GET /news/:id` - 取得單篇新聞  
- [ ] 測試 API (`Postman`)  
- [ ] **優化 API 回應格式**  
- [ ] **處理錯誤狀況**（錯誤請求、新聞不存在等）  

#### 🔹 Day 6: Hour 41 - 48 (8 小時)
- [ ] 使用 **React + TailwindCSS** 建立新聞列表頁面  
- [ ] **串接 API，顯示新聞標題、發布時間**  
- [ ] **設計基本的 UI 風格**  

#### 🔹 Day 7: Hour 49 - 56 (8 小時)
- [ ] 設計 **新聞詳情頁面**  
- [ ] **顯示完整新聞內容**  
- [ ] **支援翻譯切換**  
- [ ] **顯示 AI 生成的摘要**  

#### 🔹 Day 8: Hour 57 - 64 (8 小時)
- [ ] **完整測試 API，確保回應正確**  
- [ ] **測試前端 UI，確保新聞內容顯示**  
- [ ] 修正 **爬蟲、翻譯、儲存機制的 Bug**  

#### 🔹 Day 9: Hour 65 - 72 (8 小時)
- [ ] **優化 API 響應速度**  
- [ ] **優化 PostgreSQL 查詢**  
- [ ] **確保前端 UI 不卡頓**  
- [ ] **最終確認第一階段開發完成**  

---

### **第二階段：增強互動 & 市場指標 (Day 10 ~ Day 12, 共 20 小時)**

#### 🔹 Day 10: Hour 73 - 78 (6 小時)
- [ ] **Fear & Greed Index**  
  - [ ] 研究 Fear & Greed Index API  
  - [ ] 在後端串接 API，回傳最新的指標數據  
  - [ ] 在前端 UI 顯示 Fear & Greed 數值  
  - [ ] 使用 **Chart.js** 顯示市場趨勢 (`npm install chart.js`)  
- [ ] **山寨季指數 (Altseason Index)**  
  - [ ] 研究 Altseason Index 數據來源  
  - [ ] 在後端建立 API 端點  
  - [ ] 在前端顯示指數 & 圖表  

#### 🔹 Day 11: Hour 79 - 84 (6 小時)
- [ ] 建立 **`notes` 資料表**，支援用戶記錄新聞筆記  
- [ ] 開發 API 來 **新增 / 刪除 / 讀取筆記**  
- [ ] 確保筆記能與新聞 ID 關聯  
- [ ] 在 **新聞詳情頁面新增筆記區塊**  
- [ ] 讓使用者可以對新聞寫筆記，顯示筆記內容  
- [ ] 設計 **CRUD 操作**（增刪改查）  

#### 🔹 Day 12: Hour 85 - 92 (8 小時)
- [ ] **測試 Fear & Greed Index**  
- [ ] **測試山寨季指數**  
- [ ] **測試筆記功能**  
- [ ] 修正 **市場指標與筆記的 Bug**  

---

### **第三階段：部署 & 上線 (Day 13 ~ Day 14, 共 8 小時)**

#### 🔹 Day 13: Hour 93 - 96 (4 小時)
- [ ] **優化 API 響應速度**（減少不必要的請求）  
- [ ] **優化 PostgreSQL 查詢（加索引）**  
- [ ] **測試爬蟲，確保新聞數據穩定 & 無重複存取**  
- [ ] 測試 **所有 API 是否正常運行**  
- [ ] 測試 **所有前端功能（新聞顯示、翻譯、摘要、筆記）**  
- [ ] 修正 **UI 問題，如樣式錯位、按鈕點擊問題**  

#### 🔹 Day 14: Hour 97 - 100 (4 小時)
- [ ] **後端部署至 Railway**  
- [ ] **前端部署至 Vercel**  
- [ ] **測試線上版本，確保部署成功**  
- [ ] 記錄 **MVP 開發成果，準備 Demo 簡報**  
- [ ] 🎉 **MVP 開發完成！**  

---

## 總時數：100 小時
1. **第一階段 (Day 1 ~ Day 9)**：72 小時 (9 天 × 8 小時)  
2. **第二階段 (Day 10 ~ Day 12)**：20 小時 (6 + 6 + 8)  
3. **第三階段 (Day 13 ~ Day 14)**：8 小時 (4 + 4)  

此為 **壓縮至 100 小時** 並保留三大階段的完整開發規劃，每個 Day 後皆附上對應的小時數。